{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 583 entries, 0 to 581\nData columns (total 10 columns):\n[Place        583 non-null object\n Bib          581 non-null object\n Name         578 non-null object\n Gender       578 non-null object\n City         578 non-null object\n State        578 non-null object\n Chip Time    578 non-null object\n Chip Pace    578 non-null object\n Gun Time     578 non-null object\n Team]        578 non-null object\ndtypes: object(10)\nmemory usage: 50.1+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(583, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = \"http://www.hubertiming.com/results/2017GPTR10K\"\n",
    "html = urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "#type(soup)\n",
    "# Get the title\n",
    "title = soup.title\n",
    "#print(title)\n",
    "# Print out the text\n",
    "text = soup.get_text()\n",
    "#print(text)\n",
    "\n",
    "all_links = soup.find_all('a')\n",
    "#for link in all_links:\n",
    "    #print (link.get(\"href\"))\n",
    "rows = soup.find_all('tr')\n",
    "#print (rows[:10])\n",
    "\"\"\"for row in rows:\n",
    "    row_td = row.find_all('td')\n",
    "    str_cells = str(row_td)\n",
    "    cleantext = BeautifulSoup(str_cells, \"lxml\").get_text()\n",
    "\"\"\"\n",
    "    #print(cleantext)\n",
    "#print(row_td)\n",
    "#type(row_td)\n",
    "list_rows = []\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    str_cells = str(cells)\n",
    "    clean = re.compile('<.*?>')\n",
    "    clean2 = (re.sub(clean, '', str_cells))\n",
    "    list_rows.append(clean2)\n",
    "    #print(clean2)\n",
    "    #type(clean2)\n",
    "df = pd.DataFrame(list_rows)\n",
    "#df.head(10)\n",
    "df1 = df[0].str.split(',', expand=True)\n",
    "#df1.head(10)\n",
    "df1[0] = df1[0].str.strip('[')\n",
    "#df1[0] = df1[0].str.strip(']')\n",
    "#df1.head(10)\n",
    "\n",
    "col_labels = soup.find_all('th')\n",
    "all_header = []\n",
    "col_str = str(col_labels)\n",
    "cleantext2 = BeautifulSoup(col_str, \"lxml\").get_text()\n",
    "all_header.append(cleantext2)\n",
    "#print(all_header)\n",
    "df2 = pd.DataFrame(all_header)\n",
    "#df2.head()\n",
    "df3 = df2[0].str.split(',', expand=True)\n",
    "#df3.head()\n",
    "frames = [df3, df1]\n",
    "df4 = pd.concat(frames)\n",
    "#df4.head(10)\n",
    "df5 = df4.rename(columns=df4.iloc[0])\n",
    "df5.head()\n",
    "df5.info()\n",
    "df5.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}